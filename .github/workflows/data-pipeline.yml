name: data-pipeline-workflow

on: 
  push:
  workflow_dispatch:
  schedule:
      - cron: '30 6 * * *'

jobs:
  run-data-pipeline:
    runs-on: ubuntu-latest
    env:
      SUPABASE_URL: "https://thxvfnachnpgmeottlem.supabase.co"
      SUPABASE_KEY: "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InRoeHZmbmFjaG5wZ21lb3R0bGVtIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0Njg2ODQ1OSwiZXhwIjoyMDYyNDQ0NDU5fQ.TBgZdtH3INLZtpnraa4dfPbZ0hZHLdCoY1VKhqEv8FA"
      BUCKET_NAME: "apsbucket"
      FILE_PATH: "Configuration/config.xml"
    steps:
      - name: Show current time
        run: date
        
      - name: Checkout repo content
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run data pipeline
        run: python data_pipeline.py

      - name: Check for changes
        id: git-check
        run: |
          git config user.name 'apspayments'
          git config user.email 'aps@aps.business'
          git add .
          git diff --staged --quiet || echo "changes=true" >> $GITHUB_ENV

      - name: Commit and push if changes
        if: env.changes == 'true'
        run: |
          git commit -m "Automated update from data pipeline"
          git push
